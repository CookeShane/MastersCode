{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Author:** Shane Cooke\n",
    "\n",
    "**Date:** 26 Feb 2023\n",
    "\n",
    "**Description:** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import copy\n",
    "import numpy as np\n",
    "import statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Default JSON Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_json_file = {\n",
    "        \"info\": {},\n",
    "        \"licenses\": [],\n",
    "        \"categories\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"name\": \"Overfilled\"\n",
    "            },\n",
    "            {\n",
    "                \"id\": 2,\n",
    "                \"name\": \"NonOverfilled\"\n",
    "            }\n",
    "        ],\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "\n",
    "default_images = {\n",
    "            \"file_name\": \"Hello.jpg\",\n",
    "            \"id\": 0,\n",
    "            \"width\": 0,\n",
    "            \"height\": 0\n",
    "        }    \n",
    "\n",
    "default_annotations = {\n",
    "            \"image_id\": 0,\n",
    "            \"id\": 0,\n",
    "            \"category_id\": 1,\n",
    "            \"area\": 0,\n",
    "            \"iscrowd\": 0,\n",
    "            \"bbox\": [0, 0, 0, 0],\n",
    "            \"segmentation\": []\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Crop Images & Create New JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 'Train'\n",
    "\n",
    "image_path = f'./Dataset/HRI/Reduced/{ds}/'\n",
    "f = open(f'Dataset/HRI/Reduced/split_train.json')\n",
    "data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "save_path = './Dataset/HRI/Reduced CROP/'\n",
    "\n",
    "\n",
    "# Iterating through the json\n",
    "for count, a in enumerate(data[\"annotations\"]):\n",
    "    # Initilise Image & Annotations Details\n",
    "    image_details = default_images\n",
    "    annotation_details = default_annotations\n",
    "\n",
    "    # Get Details from JSON File\n",
    "    id = a[\"image_id\"]\n",
    "    category = a[\"category_id\"]\n",
    "    area = a['area']\n",
    "    iscrowd = a['iscrowd']\n",
    "    segmentation = a['segmentation']\n",
    "    for i in data[\"images\"]:\n",
    "        if (id == i[\"id\"]):\n",
    "            filename = i[\"file_name\"]\n",
    "    bbox = a[\"bbox\"]\n",
    "\n",
    "    # Crop Image\n",
    "    image = Image.open(image_path + filename)\n",
    "    cropped = image.crop((bbox[0], bbox[1], (bbox[0]+bbox[2]), (bbox[1]+bbox[3])))\n",
    "\n",
    "    # Save Cropped Image\n",
    "    check = os.path.isfile(f\"{save_path}{ds}/{filename}\")\n",
    "    if check == False:\n",
    "        saved_name = filename\n",
    "        cropped.save(f'{save_path}{ds}/{saved_name}')\n",
    "    else:\n",
    "        fn = filename.replace('.jpg', '')\n",
    "        saved_name = f'{fn}_{index}.jpg'\n",
    "        cropped.save(f'{save_path}{ds}/{saved_name}')\n",
    "        index = index + 1\n",
    "\n",
    "    # Populate Image & Annotations Details\n",
    "    image_details['file_name'] = saved_name\n",
    "    image_details['id'] = count\n",
    "    image_details['width'] = cropped.size[0]\n",
    "    image_details['height'] = cropped.size[1]\n",
    "    annotation_details['image_id'] = count\n",
    "    annotation_details['id'] = count\n",
    "    annotation_details['category_id'] = category\n",
    "    annotation_details['area'] = area\n",
    "    annotation_details['iscrowd'] = iscrowd\n",
    "    annotation_details['bbox'][2] = a['bbox'][2]\n",
    "    annotation_details['bbox'][3] = a['bbox'][3]\n",
    "    annotation_details['segmentation'] = segmentation\n",
    "\n",
    "    # Append Details into JSON\n",
    "    new_json_file['images'].append(copy.deepcopy(image_details))\n",
    "    new_json_file['annotations'].append(copy.deepcopy(annotation_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_file = json.dumps(new_json_file, indent=4)\n",
    "with open(f\"{save_path}split_train_crop.json\", 'w') as outfile:\n",
    "    outfile.write(j_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Resize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 480\n",
    "width = 704\n",
    "\n",
    "input_image_path = './Dataset/HRI/Control/Val/'\n",
    "output_image_path = './Dataset/HRI/Reduced/Val'\n",
    "os.makedirs(output_image_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in os.listdir(input_image_path):\n",
    "\n",
    "    image_path = os.path.join(input_image_path, image_name)\n",
    "\n",
    "    if os.path.isfile(image_path):\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = image.resize((width, height))\n",
    "\n",
    "        image = image.save(f\"{output_image_path}/{image_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f'Dataset/Personal/Control/split_val.json')\n",
    "data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "# Iterating through the json\n",
    "for a in data['images']:\n",
    "    a['width'] = 704\n",
    "    a['height'] = 480\n",
    "\n",
    "for a in data['annotations']:\n",
    "    a['bbox'][0] = (a['bbox'][0] * 704/6016)\n",
    "    a['bbox'][1] = (a['bbox'][1] * 480/4000)\n",
    "    a['bbox'][2] = (a['bbox'][2] * 704/6016)\n",
    "    a['bbox'][3] = (a['bbox'][3] * 480/4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_file = json.dumps(data, indent=4)\n",
    "with open(f\"Dataset/Personal/SizedDown/split_val.json\", 'w') as outfile:\n",
    "    outfile.write(j_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Size for Cropped Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./Dataset/HRI/Reduced CROP/split_train_crop.json')\n",
    "data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.415\n"
     ]
    }
   ],
   "source": [
    "ratio_array = []\n",
    "size_array = []\n",
    "for image in data['images']:\n",
    "    ratio = image['height'] / image['width']\n",
    "    size = [image['width'], image['height']]\n",
    "    ratio = round(ratio, 2)\n",
    "    ratio_array.append(ratio)\n",
    "    size_array.append(size)\n",
    "\n",
    "ratio_array = sorted(ratio_array)\n",
    "size_array = sorted(size_array)\n",
    "\n",
    "print(statistics.median(ratio_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162.0\n"
     ]
    }
   ],
   "source": [
    "first_elements = [sublist[0] for sublist in size_array]\n",
    "median_first_element = statistics.median(first_elements)\n",
    "print(median_first_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229.23000000000002"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_first_element * statistics.median(ratio_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24d1aeea1e4d3f699033aa98f0aed530c9ef1015c9b5c3418b9321669119b1b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
